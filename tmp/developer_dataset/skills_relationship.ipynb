{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-24T17:47:54.660885800Z",
     "start_time": "2024-01-24T17:47:54.644886100Z"
    }
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d830f46f3c3bcd5"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                  Name  \\\n0                                   Software Developer   \n1                            Junior Software Developer   \n2                                   Software Developer   \n3                                   Software Developer   \n4                            Senior Software Developer   \n..                                                 ...   \n165                            Data Scientist - Pharma   \n166       DATA SCIENTIST | MACHINE LEARNING | BIG DATA   \n167                             PDS AD&GMP Scientist I   \n168                      Junior Ethical Data Scientist   \n169  EU Institutions: AI Machine Learning Data Scie...   \n\n                                           Description  \\\n0    Miniclip is a global leader in digital games w...   \n1    NETtoWORK, azienda italiana nata nel 2016, ope...   \n2    We are looking for talented and passionate peo...   \n3    ARESYS  is a R&D oriented company with nearly ...   \n4    Il/la Candidato/a dovrà padroneggiare: \\n \\n- ...   \n..                                                 ...   \n165  Akkodis è un leader globale nel mercato dell'i...   \n166  Techyon: Information Technology Recruitment Ex...   \n167  Job DescriptionWhen you’re part of Thermo Fish...   \n168  We are looking for an extremely BOLD & VISIONA...   \n169  WHO WE ARE \\n \\n-  Etinars  is a values-focuse...   \n\n                          Location  \n0                  Genova, Liguria  \n1                     17100 Savona  \n2                      55100 Lucca  \n3               Matera, Basilicata  \n4                 Catania, Sicilia  \n..                             ...  \n165  Provincia di Torino, Piemonte  \n166          Parma, Emilia-Romagna  \n167                    20900 Monza  \n168                           None  \n169               Ispra, Lombardia  \n\n[168 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Description</th>\n      <th>Location</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Software Developer</td>\n      <td>Miniclip is a global leader in digital games w...</td>\n      <td>Genova, Liguria</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Junior Software Developer</td>\n      <td>NETtoWORK, azienda italiana nata nel 2016, ope...</td>\n      <td>17100 Savona</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Software Developer</td>\n      <td>We are looking for talented and passionate peo...</td>\n      <td>55100 Lucca</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Software Developer</td>\n      <td>ARESYS  is a R&amp;D oriented company with nearly ...</td>\n      <td>Matera, Basilicata</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Senior Software Developer</td>\n      <td>Il/la Candidato/a dovrà padroneggiare: \\n \\n- ...</td>\n      <td>Catania, Sicilia</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>165</th>\n      <td>Data Scientist - Pharma</td>\n      <td>Akkodis è un leader globale nel mercato dell'i...</td>\n      <td>Provincia di Torino, Piemonte</td>\n    </tr>\n    <tr>\n      <th>166</th>\n      <td>DATA SCIENTIST | MACHINE LEARNING | BIG DATA</td>\n      <td>Techyon: Information Technology Recruitment Ex...</td>\n      <td>Parma, Emilia-Romagna</td>\n    </tr>\n    <tr>\n      <th>167</th>\n      <td>PDS AD&amp;GMP Scientist I</td>\n      <td>Job DescriptionWhen you’re part of Thermo Fish...</td>\n      <td>20900 Monza</td>\n    </tr>\n    <tr>\n      <th>168</th>\n      <td>Junior Ethical Data Scientist</td>\n      <td>We are looking for an extremely BOLD &amp; VISIONA...</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>169</th>\n      <td>EU Institutions: AI Machine Learning Data Scie...</td>\n      <td>WHO WE ARE \\n \\n-  Etinars  is a values-focuse...</td>\n      <td>Ispra, Lombardia</td>\n    </tr>\n  </tbody>\n</table>\n<p>168 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Offers Dataset\n",
    "# TODO: change the offers dataset to one different from Turing Careers\n",
    "with sqlite3.connect('./datasets/offers_dataset.db') as offers_conn:\n",
    "    offers_frame = pd.read_sql('SELECT * FROM Offers', offers_conn)\n",
    "\n",
    "offers_frame.drop_duplicates(inplace=True)\n",
    "offers_frame"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T17:47:54.698886200Z",
     "start_time": "2024-01-24T17:47:54.662886400Z"
    }
   },
   "id": "969c95ddc2159874"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "         SKILL                  TYPE\nID                                  \n0   JavaScript  Programming Language\n1         HTML  Programming Language\n2       Python  Programming Language\n3          SQL  Programming Language\n4   TypeScript  Programming Language\n..         ...                   ...\n95         APT                  Tool\n96    Unity 3D                  Tool\n97      Pacman                  Tool\n98        pnpm                  Tool\n99         CSS  Programming Language\n\n[96 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SKILL</th>\n      <th>TYPE</th>\n    </tr>\n    <tr>\n      <th>ID</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>JavaScript</td>\n      <td>Programming Language</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HTML</td>\n      <td>Programming Language</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Python</td>\n      <td>Programming Language</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SQL</td>\n      <td>Programming Language</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TypeScript</td>\n      <td>Programming Language</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>APT</td>\n      <td>Tool</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>Unity 3D</td>\n      <td>Tool</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>Pacman</td>\n      <td>Tool</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>pnpm</td>\n      <td>Tool</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>CSS</td>\n      <td>Programming Language</td>\n    </tr>\n  </tbody>\n</table>\n<p>96 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Skills Dataset\n",
    "with sqlite3.connect('./datasets/skills_dataset.db') as skills_conn:\n",
    "    skills_frame = pd.read_sql('SELECT * FROM Skills', skills_conn, index_col='ID')\n",
    "    \n",
    "skills_frame"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T17:47:54.756941500Z",
     "start_time": "2024-01-24T17:47:54.690886Z"
    }
   },
   "id": "c8771b37a5660642"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Offers skill extraction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9919d002a3041bcd"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Windows10\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "from utils import print_performance\n",
    "\n",
    "def remove_symbols(description: str, remove_map: dict) -> str:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    for old, new in remove_map.items():\n",
    "        description = description.replace(old, new)\n",
    "    return description.lower()\n",
    "\n",
    "def extract_symbols(text: str, available_symbols: list) -> set:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    out = set()\n",
    "    for token in set(word_tokenize(text)):\n",
    "        if token.lower() in available_symbols:\n",
    "           out.add(token)\n",
    "    return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T17:47:55.291062100Z",
     "start_time": "2024-01-24T17:47:54.707886Z"
    }
   },
   "id": "1126e3a168bc0d12"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Symbols to remove\n",
    "punct = [p for p in punctuation]\n",
    "punct.remove('+')\n",
    "punct.remove('#')\n",
    "punct.remove('.')\n",
    "\n",
    "removal = {p: '' for p in punct}\n",
    "removal['\\n'] = ''\n",
    "removal['/'] = ' '\n",
    "removal['('] = ' '\n",
    "removal[')'] = ' '\n",
    "removal[','] = ' '"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T17:47:55.291062100Z",
     "start_time": "2024-01-24T17:47:55.268062800Z"
    }
   },
   "id": "cd24f3da812c025e"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\n@print_performance\\ndef extract_skills(offers_df, skills_df):\\n    skill_list = [skill.lower() for skill in skills_df['SKILL'].tolist()]\\n    skill_vectors = []\\n    for skill in skill_list:\\n        presence_vector = offers_df.Description.map(lambda desc: skill in desc.lower()).rename(skill)\\n        skill_vectors.append(presence_vector)\\n    return pd.concat([vec for vec in skill_vectors], axis=1)   \\n\""
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "@print_performance\n",
    "def extract_skills(offers_df, skills_df):\n",
    "    skill_list = [skill.lower() for skill in skills_df['SKILL'].tolist()]\n",
    "    skill_vectors = []\n",
    "    for skill in skill_list:\n",
    "        presence_vector = offers_df.Description.map(lambda desc: skill in desc.lower()).rename(skill)\n",
    "        skill_vectors.append(presence_vector)\n",
    "    return pd.concat([vec for vec in skill_vectors], axis=1)   \n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T17:47:55.300062400Z",
     "start_time": "2024-01-24T17:47:55.282063200Z"
    }
   },
   "id": "1c7924fb2477a50a"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "\n",
    "def extract_skills(offers_df, skills_df):\n",
    "    skill_list = [skill.lower() for skill in skills_df['SKILL'].tolist()]\n",
    "    skill_vectors = []\n",
    "    for skill in skill_list:\n",
    "        presence_vector = offers_df.Description.map(\n",
    "            lambda desc: skill in extract_symbols(\n",
    "                desc.lower(), \n",
    "                skill_list\n",
    "            )\n",
    "        ).rename(skill)\n",
    "        skill_vectors.append(presence_vector)\n",
    "    return pd.concat([vec for vec in skill_vectors], axis=1) \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T17:47:55.313063800Z",
     "start_time": "2024-01-24T17:47:55.300062400Z"
    }
   },
   "id": "43d3591c486c2ae0"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m skill_vector \u001B[38;5;241m=\u001B[39m \u001B[43mextract_skills\u001B[49m\u001B[43m(\u001B[49m\u001B[43moffers_frame\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskills_frame\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m skill_vector\n",
      "Cell \u001B[1;32mIn[7], line 5\u001B[0m, in \u001B[0;36mextract_skills\u001B[1;34m(offers_df, skills_df)\u001B[0m\n\u001B[0;32m      3\u001B[0m skill_vectors \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m skill \u001B[38;5;129;01min\u001B[39;00m skill_list:\n\u001B[1;32m----> 5\u001B[0m     presence_vector \u001B[38;5;241m=\u001B[39m \u001B[43moffers_df\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDescription\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdesc\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mskill\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mextract_symbols\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdesc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlower\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m            \u001B[49m\u001B[43mskill_list\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mrename(skill)\n\u001B[0;32m     11\u001B[0m     skill_vectors\u001B[38;5;241m.\u001B[39mappend(presence_vector)\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pd\u001B[38;5;241m.\u001B[39mconcat([vec \u001B[38;5;28;01mfor\u001B[39;00m vec \u001B[38;5;129;01min\u001B[39;00m skill_vectors], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\RecommenderSystem_TC\\venv\\lib\\site-packages\\pandas\\core\\series.py:4544\u001B[0m, in \u001B[0;36mSeries.map\u001B[1;34m(self, arg, na_action)\u001B[0m\n\u001B[0;32m   4464\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmap\u001B[39m(\n\u001B[0;32m   4465\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   4466\u001B[0m     arg: Callable \u001B[38;5;241m|\u001B[39m Mapping \u001B[38;5;241m|\u001B[39m Series,\n\u001B[0;32m   4467\u001B[0m     na_action: Literal[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   4468\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Series:\n\u001B[0;32m   4469\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   4470\u001B[0m \u001B[38;5;124;03m    Map values of Series according to an input mapping or function.\u001B[39;00m\n\u001B[0;32m   4471\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4542\u001B[0m \u001B[38;5;124;03m    dtype: object\u001B[39;00m\n\u001B[0;32m   4543\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 4544\u001B[0m     new_values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_map_values\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mna_action\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4545\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_constructor(new_values, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\u001B[38;5;241m.\u001B[39m__finalize__(\n\u001B[0;32m   4546\u001B[0m         \u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmap\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   4547\u001B[0m     )\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\RecommenderSystem_TC\\venv\\lib\\site-packages\\pandas\\core\\base.py:921\u001B[0m, in \u001B[0;36mIndexOpsMixin._map_values\u001B[1;34m(self, mapper, na_action, convert)\u001B[0m\n\u001B[0;32m    918\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arr, ExtensionArray):\n\u001B[0;32m    919\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mmap(mapper, na_action\u001B[38;5;241m=\u001B[39mna_action)\n\u001B[1;32m--> 921\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43malgorithms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mna_action\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\RecommenderSystem_TC\\venv\\lib\\site-packages\\pandas\\core\\algorithms.py:1814\u001B[0m, in \u001B[0;36mmap_array\u001B[1;34m(arr, mapper, na_action, convert)\u001B[0m\n\u001B[0;32m   1812\u001B[0m values \u001B[38;5;241m=\u001B[39m arr\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m   1813\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m na_action \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1814\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1815\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1816\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m lib\u001B[38;5;241m.\u001B[39mmap_infer_mask(\n\u001B[0;32m   1817\u001B[0m         values, mapper, mask\u001B[38;5;241m=\u001B[39misna(values)\u001B[38;5;241m.\u001B[39mview(np\u001B[38;5;241m.\u001B[39muint8), convert\u001B[38;5;241m=\u001B[39mconvert\n\u001B[0;32m   1818\u001B[0m     )\n",
      "File \u001B[1;32mlib.pyx:2926\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[1;34m()\u001B[0m\n",
      "Cell \u001B[1;32mIn[7], line 6\u001B[0m, in \u001B[0;36mextract_skills.<locals>.<lambda>\u001B[1;34m(desc)\u001B[0m\n\u001B[0;32m      3\u001B[0m skill_vectors \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m skill \u001B[38;5;129;01min\u001B[39;00m skill_list:\n\u001B[0;32m      5\u001B[0m     presence_vector \u001B[38;5;241m=\u001B[39m offers_df\u001B[38;5;241m.\u001B[39mDescription\u001B[38;5;241m.\u001B[39mmap(\n\u001B[1;32m----> 6\u001B[0m         \u001B[38;5;28;01mlambda\u001B[39;00m desc: skill \u001B[38;5;129;01min\u001B[39;00m \u001B[43mextract_symbols\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdesc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlower\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m            \u001B[49m\u001B[43mskill_list\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m     )\u001B[38;5;241m.\u001B[39mrename(skill)\n\u001B[0;32m     11\u001B[0m     skill_vectors\u001B[38;5;241m.\u001B[39mappend(presence_vector)\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pd\u001B[38;5;241m.\u001B[39mconcat([vec \u001B[38;5;28;01mfor\u001B[39;00m vec \u001B[38;5;129;01min\u001B[39;00m skill_vectors], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "Cell \u001B[1;32mIn[4], line 21\u001B[0m, in \u001B[0;36mextract_symbols\u001B[1;34m(text, available_symbols)\u001B[0m\n\u001B[0;32m     19\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m token \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mset\u001B[39m(word_tokenize(text)):\n\u001B[1;32m---> 21\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mtoken\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlower\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;129;01min\u001B[39;00m available_symbols:\n\u001B[0;32m     22\u001B[0m        out\u001B[38;5;241m.\u001B[39madd(token)\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "skill_vector = extract_skills(offers_frame, skills_frame)\n",
    "skill_vector"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T17:48:04.118419600Z",
     "start_time": "2024-01-24T17:47:55.314063Z"
    }
   },
   "id": "9525c7ce918e4add"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Distribution Analysis\n",
    "Given that the dataset is imbalanced more data/better data should be acquired"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f3e68e5a3c31b7d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# --- Unbalanced Data\n",
    "skills_headers = skill_vector.columns.tolist()\n",
    "#skills_headers.remove('c')\n",
    "#skills_headers.remove('go')\n",
    "skill_vector = skill_vector[skills_headers]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T17:48:04.132418800Z",
     "start_time": "2024-01-24T17:48:04.120420100Z"
    }
   },
   "id": "76ef166c1be18436"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "skill_counts = skill_vector.sum()\n",
    "skill_counts.rename(\"Count\", inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-24T17:48:04.122420Z"
    }
   },
   "id": "d5de023f2be2f113"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_skills(count_frame):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.barplot(x=count_frame.values, y=count_frame.index, palette=\"viridis\")\n",
    "    plt.title(\"Distribution of Skills in the Dataset\")\n",
    "    plt.xlabel(\"Count\")\n",
    "    plt.ylabel(\"Skills\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-24T17:48:04.124419100Z"
    }
   },
   "id": "25772814cd6d71b6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "selected_skills = skill_counts[skill_counts >= 6].index\n",
    "skill_vector = skill_vector[selected_skills]\n",
    "skill_counts = skill_vector.sum()\n",
    "\n",
    "plot_skills(skill_counts.sort_values(ascending=False))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-24T17:48:04.125421100Z"
    }
   },
   "id": "ecaaaf28f7bab220"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Association Rule Mining"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "526509500ec32914"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### FP max Algorithm\n",
    "One red-flag is that it doesn't show a single item set with HTML and CSS together."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6070e374538db1c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import fpmax\n",
    "\n",
    "@print_performance\n",
    "def task_fp_max(vect):\n",
    "    return fpmax(vect, use_colnames=True, min_support=0.05)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-24T17:48:04.126419200Z"
    }
   },
   "id": "cc038a4611ed3711"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "skill_sets = task_fp_max(skill_vector)\n",
    "skill_sets"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-24T17:48:04.128419600Z"
    }
   },
   "id": "c9708a768beeeb21"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clustering Algorithm"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "691e8f9dc0e34d04"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-24T17:48:04.129419200Z"
    }
   },
   "id": "cf4abb76e16ad281"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-24T17:48:04.130419900Z"
    }
   },
   "id": "8b6e950b21b55a10"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Export"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6a3def7413bd719"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with sqlite3.connect('./datasets/skill_sets.db') as out_conn:\n",
    "    out_curs = out_conn.cursor()\n",
    "    out_curs.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS SkillSets (\n",
    "            ID INTEGER PRIMARY KEY,\n",
    "            SKILLS TEXT\n",
    "        )    \n",
    "    ''')\n",
    "\n",
    "    i = -1\n",
    "    for skill_set in skill_sets['itemsets'].tolist():\n",
    "        if len(skill_set) > 1: \n",
    "            skill_list = []\n",
    "            \n",
    "            for skill in skill_set:\n",
    "                skill_list.append(skill)\n",
    "                \n",
    "            i += 1\n",
    "            out_curs.execute('''INSERT INTO SkillSets VALUES (?, ?)''', (i, ', '.join(skill_list)))\n",
    "            \n",
    "    out_conn.commit()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-24T17:48:04.131419500Z"
    }
   },
   "id": "ca1021e2487d1728"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with sqlite3.connect('./datasets/skill_sets.db') as test_conn:\n",
    "        test_frame = pd.read_sql('SELECT * FROM SkillSets', test_conn, index_col='ID')\n",
    "\n",
    "test_frame"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T17:48:04.132418800Z",
     "start_time": "2024-01-24T17:48:04.132418800Z"
    }
   },
   "id": "fd7ee1cca60fef75"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-24T17:48:04.133420100Z"
    }
   },
   "id": "9eff230a95affba1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
